{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. úloha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "TODO pridat zvolenu parametrizaciu Weibullovho rozdelenia, log-vierohodnostnu funkciu a parcialne derivacie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data_2024.xlsx\"\n",
    "wb = openpyxl.load_workbook(path)\n",
    "sheet = wb[\"Data_věrohodnost\"]\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "uncensored_data = []\n",
    "censored_data = []\n",
    "\n",
    "for row in sheet.iter_rows(min_row=2, max_col=2, values_only=True):\n",
    "    data.append(row[1])\n",
    "    \n",
    "    if(row[0] == 0):\n",
    "        uncensored_data.append(row[1])\n",
    "    else:\n",
    "        censored_data.append(row[1])\n",
    "    \n",
    "uncensored_data = np.array(uncensored_data)\n",
    "censored_data = np.array(censored_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, uncensored_data, censored_data):\n",
    "    k, lambd = params\n",
    "    \n",
    "    ll_uncensored = np.sum(np.log(k/lambd) + np.log((uncensored_data/lambd)**(k-1)) - (uncensored_data/lambd)**k)\n",
    "    \n",
    "    \n",
    "    ll_censored = np.sum(-(censored_data / lambd)**k)\n",
    "\n",
    "    return -(ll_uncensored + ll_censored)\n",
    "\n",
    "def log_likelihood_exp(params, uncensored_data, censored_data):\n",
    "    lambd = params\n",
    "\n",
    "    ll_uncensored = np.sum(np.log(1/lambd) + np.log((uncensored_data/lambd)**(1-1)) - (uncensored_data/lambd)**1)\n",
    "    \n",
    "    \n",
    "    ll_censored = np.sum(-(censored_data / lambd)**1)\n",
    "\n",
    "    return -(ll_uncensored + ll_censored)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "initial_guess = [1.5, np.mean(data)]\n",
    "\n",
    "result = scipy.optimize.minimize(fun=log_likelihood, x0=initial_guess, args=(uncensored_data, censored_data), method='BFGS')\n",
    "\n",
    "k_opt, lambd_opt = result.x\n",
    "print(f\"est. params: k = {k_opt:.4f}, lambda = {lambd_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess_exp = [np.mean(data)]\n",
    "\n",
    "result_exp = scipy.optimize.minimize(fun=log_likelihood_exp, x0=initial_guess_exp, args=(uncensored_data, censored_data), method='BFGS')\n",
    "\n",
    "L1 = result.fun\n",
    "\n",
    "L2 = result_exp.fun\n",
    "\n",
    "Stat = 2 * (L2 - L1)\n",
    "\n",
    "print(Stat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doplnok kritického oboru: <0; 5.024>\n",
    "592.39 nepatrí do doplnku kritického oboru, teda zamietame H0: Exponenciálne rozdelenie je postačujúce\n",
    "Prijímame H1: Exponenciálne rozdelenie nie je postačujúce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambd_opt * gamma(1+1/k_opt)\n",
    "tencentil = lambd_opt*(-np.log(1-0.1))**(1/k_opt)\n",
    "\n",
    "print(\"mean:\", mean)\n",
    "print(\"tencentil:\", tencentil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. úloha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path, sheet_name='Data_regrese', usecols='A:E', engine='openpyxl')\n",
    "df = df.drop(\"InteractingPct\", axis=1)\n",
    "x_mean = df['ActiveUsers'].mean()\n",
    "x_std = df['ActiveUsers'].std()\n",
    "df[\"ActiveUsers\"] = df[\"ActiveUsers\"].apply(lambda x: (x - x_mean) / x_std)\n",
    "\n",
    "x_mean = df['ScrollingPct'].mean()\n",
    "x_std = df['ScrollingPct'].std()\n",
    "\n",
    "df['ScrollingPct'] = df['ScrollingPct'].apply(lambda x: (x - x_mean) / x_std)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['OSType'], drop_first=True)\n",
    "\n",
    "df = df.astype(float)\n",
    "\n",
    "\n",
    "numeric_predictors = ['ActiveUsers', 'ScrollingPct', 'OSType_iOS', 'OSType_Windows', 'OSType_MacOS']\n",
    "\n",
    "for col in numeric_predictors:\n",
    "    df[f'{col}^2'] = df[col] ** 2\n",
    "\n",
    "for col1, col2 in combinations(numeric_predictors, 2):\n",
    "    df[f'{col1}:{col2}'] = df[col1] * df[col2]\n",
    "\n",
    "df = df.drop(columns=['OSType_iOS:OSType_Windows', 'OSType_iOS:OSType_MacOS', 'OSType_Windows:OSType_MacOS', 'OSType_Windows^2', 'OSType_MacOS^2', 'OSType_iOS^2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Ping [ms]'])\n",
    "y = df['Ping [ms]']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_iOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_Windows'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_MacOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct^2'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'VIF': [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "})\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = full_model.get_influence()\n",
    "leverage = influence.hat_matrix_diag\n",
    "cooks_d = influence.cooks_distance\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "studentized_residuals = influence.resid_studentized_external\n",
    "studentized_residuals_pvalues = 2 * (1 - scipy.stats.t.cdf(np.abs(studentized_residuals), df=df.shape[0]-len(full_model.params)))\n",
    "\n",
    "outl_stats_df = pd.DataFrame({\n",
    "    'Leverage': leverage,\n",
    "    'Standardized Residuals': standardized_residuals,\n",
    "    'Studentized Residuals': studentized_residuals,\n",
    "    'Studentized Residuals p-value': studentized_residuals_pvalues,\n",
    "    'Cook\\'s Distance': cooks_d[0],\n",
    "    'Cook\\'s Distance_p-value': cooks_d[1]\n",
    "}, index=df.index)\n",
    "#vyber jen \"zajímavý\" hodnoty\n",
    "outl_stats_df = outl_stats_df[(outl_stats_df['Leverage'] > 3*len(full_model.params)/df.shape[0]) | (np.abs(outl_stats_df['Standardized Residuals']) > 2) | (outl_stats_df['Cook\\'s Distance_p-value'] < 0.05)]\n",
    "\n",
    "summary_frame = influence.summary_frame()\n",
    "\n",
    "print(outl_stats_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=[255, 476])\n",
    "\n",
    "numeric_predictors = ['ActiveUsers', 'ScrollingPct', 'OSType_iOS', 'OSType_Windows', 'OSType_MacOS']\n",
    "\n",
    "for col in numeric_predictors:\n",
    "    df[f'{col}^2'] = df[col] ** 2\n",
    "\n",
    "for col1, col2 in combinations(numeric_predictors, 2):\n",
    "    df[f'{col1}:{col2}'] = df[col1] * df[col2]\n",
    "\n",
    "df = df.drop(columns=['OSType_iOS:OSType_Windows', 'OSType_iOS:OSType_MacOS', 'OSType_Windows:OSType_MacOS', 'OSType_Windows^2', 'OSType_MacOS^2', 'OSType_iOS^2'])\n",
    "\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO zapisat rovnicu finalneho modelu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
