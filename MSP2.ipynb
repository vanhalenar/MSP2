{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. úloha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"IMG_1782.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data_2024.xlsx\"\n",
    "wb = openpyxl.load_workbook(path)\n",
    "sheet = wb[\"Data_věrohodnost\"]\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "uncensored_data = []\n",
    "censored_data = []\n",
    "\n",
    "for row in sheet.iter_rows(min_row=2, max_col=2, values_only=True):\n",
    "    data.append(row[1])\n",
    "    \n",
    "    if(row[0] == 0):\n",
    "        uncensored_data.append(row[1])\n",
    "    else:\n",
    "        censored_data.append(row[1])\n",
    "    \n",
    "uncensored_data = np.array(uncensored_data)\n",
    "censored_data = np.array(censored_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, uncensored_data, censored_data):\n",
    "    k, lambd = params\n",
    "    \n",
    "    ll_uncensored = np.sum(np.log(k/lambd) + np.log((uncensored_data/lambd)**(k-1)) - (uncensored_data/lambd)**k)\n",
    "    \n",
    "    \n",
    "    ll_censored = np.sum(-(censored_data / lambd)**k)\n",
    "\n",
    "    return -(ll_uncensored + ll_censored)\n",
    "\n",
    "def log_likelihood_exp(params, uncensored_data, censored_data):\n",
    "    lambd = params\n",
    "\n",
    "    ll_uncensored = np.sum(np.log(1/lambd) + np.log((uncensored_data/lambd)**(1-1)) - (uncensored_data/lambd)**1)\n",
    "    \n",
    "    \n",
    "    ll_censored = np.sum(-(censored_data / lambd)**1)\n",
    "\n",
    "    return -(ll_uncensored + ll_censored)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "initial_guess = [1.5, np.mean(data)]\n",
    "\n",
    "result = scipy.optimize.minimize(fun=log_likelihood, x0=initial_guess, args=(uncensored_data, censored_data), method='BFGS')\n",
    "\n",
    "k_opt, lambd_opt = result.x\n",
    "print(f\"est. params: k = {k_opt:.4f}, lambda = {lambd_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess_exp = [np.mean(data)]\n",
    "\n",
    "result_exp = scipy.optimize.minimize(fun=log_likelihood_exp, x0=initial_guess_exp, args=(uncensored_data, censored_data), method='BFGS')\n",
    "\n",
    "L1 = result.fun\n",
    "\n",
    "L2 = result_exp.fun\n",
    "\n",
    "Stat = 2 * (L2 - L1)\n",
    "\n",
    "print(Stat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doplnok kritického oboru: <0; 5.024>\n",
    "592.39 nepatrí do doplnku kritického oboru, teda zamietame H0: Exponenciálne rozdelenie je postačujúce\n",
    "Prijímame H1: Exponenciálne rozdelenie nie je postačujúce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambd_opt * gamma(1+1/k_opt)\n",
    "tencentil = lambd_opt*(-np.log(1-0.1))**(1/k_opt)\n",
    "\n",
    "print(\"mean:\", mean)\n",
    "print(\"tencentil:\", tencentil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. úloha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path, sheet_name='Data_regrese', usecols='A:E', engine='openpyxl')\n",
    "df = df.drop(\"InteractingPct\", axis=1)\n",
    "act_users_mean = df['ActiveUsers'].mean()\n",
    "act_users_std = df['ActiveUsers'].std()\n",
    "df[\"ActiveUsers\"] = df[\"ActiveUsers\"].apply(lambda x: (x - act_users_mean) / act_users_std)\n",
    "\n",
    "scroll_mean = df['ScrollingPct'].mean()\n",
    "scroll_std = df['ScrollingPct'].std()\n",
    "\n",
    "df['ScrollingPct'] = df['ScrollingPct'].apply(lambda x: (x - scroll_mean) / scroll_std)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['OSType'], drop_first=True)\n",
    "\n",
    "df = df.astype(float)\n",
    "\n",
    "\n",
    "numeric_predictors = ['ActiveUsers', 'ScrollingPct', 'OSType_iOS', 'OSType_Windows', 'OSType_MacOS']\n",
    "\n",
    "for col in numeric_predictors:\n",
    "    df[f'{col}^2'] = df[col] ** 2\n",
    "\n",
    "for col1, col2 in combinations(numeric_predictors, 2):\n",
    "    df[f'{col1}:{col2}'] = df[col1] * df[col2]\n",
    "\n",
    "df = df.drop(columns=['OSType_iOS:OSType_Windows', 'OSType_iOS:OSType_MacOS', 'OSType_Windows:OSType_MacOS', 'OSType_Windows^2', 'OSType_MacOS^2', 'OSType_iOS^2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Ping [ms]'])\n",
    "y = df['Ping [ms]']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_iOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_Windows'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_MacOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct^2'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = full_model.get_influence()\n",
    "leverage = influence.hat_matrix_diag\n",
    "cooks_d = influence.cooks_distance\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "studentized_residuals = influence.resid_studentized_external\n",
    "studentized_residuals_pvalues = 2 * (1 - scipy.stats.t.cdf(np.abs(studentized_residuals), df=df.shape[0]-len(full_model.params)))\n",
    "\n",
    "outl_stats_df = pd.DataFrame({\n",
    "    'Leverage': leverage,\n",
    "    'Standardized Residuals': standardized_residuals,\n",
    "    'Studentized Residuals': studentized_residuals,\n",
    "    'Studentized Residuals p-value': studentized_residuals_pvalues,\n",
    "    'Cook\\'s Distance': cooks_d[0],\n",
    "    'Cook\\'s Distance_p-value': cooks_d[1]\n",
    "}, index=df.index)\n",
    "#vyber jen \"zajímavý\" hodnoty\n",
    "outl_stats_df = outl_stats_df[(outl_stats_df['Leverage'] > 3*len(full_model.params)/df.shape[0]) | (np.abs(outl_stats_df['Standardized Residuals']) > 2) | (outl_stats_df['Cook\\'s Distance_p-value'] < 0.05)]\n",
    "\n",
    "summary_frame = influence.summary_frame()\n",
    "\n",
    "print(outl_stats_df)\n",
    "\n",
    "df = df.drop(index=[255, 476])\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_predictors:\n",
    "    df[f'{col}^2'] = df[col] ** 2\n",
    "\n",
    "for col1, col2 in combinations(numeric_predictors, 2):\n",
    "    df[f'{col1}:{col2}'] = df[col1] * df[col2]\n",
    "\n",
    "df = df.drop(columns=['OSType_iOS:OSType_Windows', 'OSType_iOS:OSType_MacOS', 'OSType_Windows:OSType_MacOS', 'OSType_Windows^2', 'OSType_MacOS^2', 'OSType_iOS^2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Ping [ms]'])\n",
    "y = df['Ping [ms]']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_iOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_Windows'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct:OSType_MacOS'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "#print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['ScrollingPct^2'])\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'VIF': [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "})\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values = full_model.fittedvalues\n",
    "\n",
    "residuals = full_model.resid\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(fitted_values, residuals, alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sm.qqplot(residuals, line='45', fit=True)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 finálna rovnica modelu\n",
    "\n",
    "Ping = 51.2936 + 10.0457\\*ActiveUsers - 5.1410\\*ScrollingPct + 9.0073\\*OSType_MacOS + 3.6657\\*OSType_Windows - 5.7223 \\* OSType_iOS - 3.0081 \\* ActiveUsers^2 + 2.5596 \\* ActiveUsers\\*ScrollingPct - 2.7423 \\* ActiveUsers \\* OSType_iOS - 1.9127 \\* ActiveUsers \\* OSType_Windows + 4.4373 \\* ActiveUsers \\* OSType_MacOS\n",
    "\n",
    "### 2.1.2 Splnenie predpokladov a základné regresné diagnostiky\n",
    "\n",
    "- Závislosť medzi prediktormi a závislou premennou je lineárna: \n",
    "    - Hodnoty v grafe Residuals vs. Fitted values sú náhodne porozhadzované okolo nuly.\n",
    "- Reziduá sú nezávislé\n",
    "    - Výsledok Durbin-Watson testu je 1.99, čo neindikuje žiadnu autokoreláciu reziduí\n",
    "- Homoskedasticita\n",
    "    - Z grafu Residuals vs. Fitted values je vidieť, že rozloženie hodnôt je všade cca. rovnaké, teda neukazuje žiadnu významnú heteroskedasticitu\n",
    "- Normálne rozloženie reziduí\n",
    "    - Viz Histogram reziduí a Q-Q plot\n",
    "- Žiadna multikolinearita\n",
    "    - VIF všetkých premenných je < 5\n",
    "\n",
    "Počas regresného modelovania boli nájdené dve odľahlé hodnoty podľa Studentizovaných reziduí. Tieto boli odstránené, čo zvýšilo kvalitu modelu.\n",
    "R-squared a Adj. R-squared vyšli pomerne vysoké čísla, čo naznačuje, že model pasuje na dáta. Hodnoty sú tiež podobné, čo naznačuje, že jednotlivé parametre správne prispievajú a v modeli neostali zbytočné premenné.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Najproblematickejšie nastavenie parametrov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ping = full_model._results.predict().argmax()\n",
    "\n",
    "worst_params = df.iloc[max_ping]\n",
    "\n",
    "print(worst_params)\n",
    "\n",
    "ActUsers = worst_params[\"ActiveUsers\"] * act_users_std + act_users_mean\n",
    "ScrlPct = worst_params[\"ScrollingPct\"] * scroll_std + scroll_mean\n",
    "IntPct = 1 - ScrlPct\n",
    "\n",
    "print(\"Najhoršie nastavenie parametrov: ActiveUsers: \", ActUsers, \" InteractingPct: \", IntPct, \" ScrollingPct: \", ScrlPct, \"OSType: MacOS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Odhad odozvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_act_users = df[\"ActiveUsers\"].mean()\n",
    "mean_scrl_pct = df[\"ScrollingPct\"].mean()\n",
    "\n",
    "row = X.iloc[23].copy()\n",
    "row['ActiveUsers'] = mean_act_users\n",
    "row['ScrollingPct'] = mean_scrl_pct\n",
    "row['OSType_Windows'] = 1.0\n",
    "row['OSType_iOS'] = 0.0\n",
    "row['ActiveUsers^2'] = mean_act_users ** 2\n",
    "row['ActiveUsers:ScrollingPct'] = mean_act_users * mean_scrl_pct\n",
    "row['ActiveUsers:OSType_iOS'] = 0.0\n",
    "row['ActiveUsers:OSType_Windows'] = mean_act_users\n",
    "\n",
    "prediction = full_model.predict(row)\n",
    "\n",
    "print(\"Odhadovaná odozva: \", prediction.iloc[0], \"ms\")\n",
    "\n",
    "conf_int = full_model.get_prediction(row).conf_int(0.05)\n",
    "print (\"CI: \",conf_int)\n",
    "\n",
    "t_stat = scipy.stats.t.ppf(1 - 0.025, df=df.shape[0] - len(full_model.params))\n",
    "\n",
    "cov_matrix = full_model.cov_params()\n",
    "X_new = row.values.reshape(1, -1)\n",
    "\n",
    "se_prediction = np.sqrt(np.dot(np.dot(X_new, cov_matrix), X_new.T))[0, 0]\n",
    "\n",
    "pi_upper = prediction.iloc[0] + t_stat * se_prediction\n",
    "pi_lower = prediction.iloc[0] - t_stat * se_prediction\n",
    "print(\"PI: \", pi_lower, pi_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Zhodnotenie\n",
    "\n",
    "p-hodnoty prediktorov sú nízke, R-squared aj adj. R-squared naznačujú že model je schopný, VIF je < 5 pre všetky prediktory - z toho mi vyplýva, že model je použiteľný."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
